{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "import matplotlib.pyplot as plt \n",
    "import sys \n",
    "sys.path.append('../') \n",
    "from layer_approx_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "test_images = np.expand_dims(test_images.astype(\"float32\")/255.0,-1)\n",
    "test_labels = test_labels.astype(\"float32\")\n",
    "train_images = np.expand_dims(train_images.astype(\"float32\")/255.0,-1)\n",
    "train_labels = train_labels.astype(\"float32\")\n",
    "val_images = train_images[-10000:]\n",
    "val_labels = train_labels[-10000:]\n",
    "train_images = train_images[:-10000]\n",
    "train_labels = train_labels[:-10000]\n",
    "# random shuffling is very very important ...\n",
    "np.random.seed(8)\n",
    "ind = np.random.choice(train_images.shape[0], train_images.shape[0], replace=False)\n",
    "train_images = train_images[ind, :]\n",
    "train_labels = train_labels[ind]\n",
    "\n",
    "train_images = train_images[:512]\n",
    "train_labels = train_labels[:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4341 - sparse_categorical_accuracy: 0.8698\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)     (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)     (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "origLoss, origAccuracy = loadedModel.evaluate(test_images, test_labels, batch_size=128)\n",
    "loadedModel.summary()\n",
    "initial_size = 6*5*5*1 + 6  + 16*5*5*6 + 16 + 256*120 + 120 + 120*84 + 84 + 84*10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseLayerlocal(keras.layers.Layer):\n",
    "    def __init__(self, n_input=None, n_output=None, Wip=None, Mip=None, bias_ip=None):\n",
    "        \n",
    "        super(sparseLayerlocal, self).__init__()\n",
    "        \n",
    "        if Wip is None:\n",
    "            w_init = tf.random_normal_initializer()\n",
    "            self.W = tf.Variable(initial_value=w_init(shape=(n_input,n_output)),\n",
    "                                dtype=\"float32\",\n",
    "                                trainable=True)\n",
    "        else:\n",
    "            self.W = tf.Variable(initial_value=Wip, \n",
    "                                dtype=\"float32\",\n",
    "                                trainable=True)\n",
    "                    \n",
    "        if Mip is None:\n",
    "            self.M = tf.Variable(intial_value = tf.ones(shape=(n_input,n_output), dtype=\"float32\"),\n",
    "                                     dtype=\"float32\",\n",
    "                                     trainable=False)\n",
    "        else:\n",
    "            self.M = tf.Variable(initial_value = Mip,\n",
    "                                 dtype=\"float32\",\n",
    "                                 trainable=False)\n",
    "        \n",
    "        if bias_ip is None:\n",
    "            b_init = tf.zeros_initializer()\n",
    "            self.b = tf.Variable(initial_value=b_init(shape=(n_output,)), \n",
    "                             dtype=\"float32\", \n",
    "                             trainable=True)\n",
    "        else:\n",
    "            self.b = tf.Variable(initial_value=bias_ip, \n",
    "                             dtype=\"float32\", \n",
    "                             trainable=True)\n",
    "            \n",
    "    def call(self, x):\n",
    "        x = tf.matmul(x, tf.multiply(self.M, self.W)) + self.b\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4854 - sparse_categorical_accuracy: 0.8573\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3262 - sparse_categorical_accuracy: 0.9004 - val_loss: 0.4145 - val_sparse_categorical_accuracy: 0.8711\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4151 - sparse_categorical_accuracy: 0.8728\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.8533\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.3663 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.4796 - val_sparse_categorical_accuracy: 0.8467\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8499\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.8516\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3334 - sparse_categorical_accuracy: 0.9004 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.8590\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4691 - sparse_categorical_accuracy: 0.8607\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5042 - sparse_categorical_accuracy: 0.8502\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3105 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.8665\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8664\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5355 - sparse_categorical_accuracy: 0.8372\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.9004 - val_loss: 0.5391 - val_sparse_categorical_accuracy: 0.8372\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.8302\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5544 - sparse_categorical_accuracy: 0.8322\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.8926 - val_loss: 0.5107 - val_sparse_categorical_accuracy: 0.8409\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5266 - sparse_categorical_accuracy: 0.8388\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5807 - sparse_categorical_accuracy: 0.8232\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3796 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.4707 - val_sparse_categorical_accuracy: 0.8556\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8539\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5997 - sparse_categorical_accuracy: 0.8160\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4090 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.5223 - val_sparse_categorical_accuracy: 0.8348\n",
      "79/79 [==============================] - 0s 990us/step - loss: 0.5217 - sparse_categorical_accuracy: 0.8361\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6227 - sparse_categorical_accuracy: 0.8072\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.4418 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.5189 - val_sparse_categorical_accuracy: 0.8334\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.8310\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7111 - sparse_categorical_accuracy: 0.7656\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 0.5112 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.5363 - val_sparse_categorical_accuracy: 0.8291\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.8259\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8626 - sparse_categorical_accuracy: 0.7005\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6277 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.6417 - val_sparse_categorical_accuracy: 0.7848\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6513 - sparse_categorical_accuracy: 0.7765\n"
     ]
    }
   ],
   "source": [
    "#DLR Layer 1\n",
    "U_dict_layer1 = np.load('approx_matrices/DLR_layer_1_Run2_N_512.npy',allow_pickle=True).item()\n",
    "thr = 0.5\n",
    "acc_DLR = []\n",
    "acc_DLR_finetuned = []\n",
    "ranks = []\n",
    "idx = 5\n",
    "for epsilon, W in U_dict_layer1.items():\n",
    "\n",
    "    [U,S,V] = np.linalg.svd(W)\n",
    "    #print(S)\n",
    "    rank = np.count_nonzero(S>thr)\n",
    "    U = np.dot(U[:,:rank], np.diag(S[:rank]))\n",
    "    V = V[:rank, :]\n",
    "  \n",
    "                            \n",
    "    ranks.append(rank)\n",
    "                            \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    bias = getLayerBias(loadedModel, idx)\n",
    "    \n",
    "    low_rank_layer = lowrankLayer(W.shape[0], W.shape[1], rank)\n",
    "    dum = low_rank_layer(tf.ones(shape=(1, W.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer.set_weights([U,V,bias])\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == idx:\n",
    "            new_layer_list.append(low_rank_layer)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_DLR.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=1, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_DLR_finetuned.append(acc)     \n",
    "\n",
    "acc_DLR_layer1 = np.array(acc_DLR)\n",
    "acc_DLR_finetuned_layer1 = np.array(acc_DLR_finetuned)\n",
    "ranks_layer1 = np.array(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75, 58, 37, 24, 18, 15, 12, 10, 10,  8,  6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_with_layer_1 = []\n",
    "for rank in ranks_layer1:\n",
    "    size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  (256 + 120)*rank + 120 +  120*84 + 84 +  84*10 +10\n",
    "    size_with_layer_1.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5373 - sparse_categorical_accuracy: 0.8359\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3550 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.8740\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9277 - val_loss: 0.3731 - val_sparse_categorical_accuracy: 0.8797\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.3760 - sparse_categorical_accuracy: 0.8851\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5316 - sparse_categorical_accuracy: 0.8379\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3754 - sparse_categorical_accuracy: 0.8711 - val_loss: 0.5110 - val_sparse_categorical_accuracy: 0.8454\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2680 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.4039 - val_sparse_categorical_accuracy: 0.8768\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4136 - sparse_categorical_accuracy: 0.8742\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.8267\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3713 - sparse_categorical_accuracy: 0.8848 - val_loss: 0.4393 - val_sparse_categorical_accuracy: 0.8643\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.2924 - sparse_categorical_accuracy: 0.9004 - val_loss: 0.4058 - val_sparse_categorical_accuracy: 0.8743\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4168 - sparse_categorical_accuracy: 0.8724\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7608 - sparse_categorical_accuracy: 0.7470\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4259 - sparse_categorical_accuracy: 0.8574 - val_loss: 0.4880 - val_sparse_categorical_accuracy: 0.8487\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3393 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4275 - val_sparse_categorical_accuracy: 0.8707\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4272 - sparse_categorical_accuracy: 0.8678\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.9783 - sparse_categorical_accuracy: 0.6828\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4928 - sparse_categorical_accuracy: 0.8379 - val_loss: 0.4794 - val_sparse_categorical_accuracy: 0.8491\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3215 - sparse_categorical_accuracy: 0.9102 - val_loss: 0.4244 - val_sparse_categorical_accuracy: 0.8707\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4331 - sparse_categorical_accuracy: 0.8652\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.0072 - sparse_categorical_accuracy: 0.6720\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 1s 49ms/step - loss: 0.4881 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.5137 - val_sparse_categorical_accuracy: 0.8389\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3324 - sparse_categorical_accuracy: 0.9062 - val_loss: 0.4231 - val_sparse_categorical_accuracy: 0.8747\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4238 - sparse_categorical_accuracy: 0.8716\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.9890 - sparse_categorical_accuracy: 0.6721\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5084 - sparse_categorical_accuracy: 0.8457 - val_loss: 0.5147 - val_sparse_categorical_accuracy: 0.8388\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3676 - sparse_categorical_accuracy: 0.8926 - val_loss: 0.4702 - val_sparse_categorical_accuracy: 0.8579\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4749 - sparse_categorical_accuracy: 0.8493\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.3315 - sparse_categorical_accuracy: 0.5570\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6084 - sparse_categorical_accuracy: 0.8027 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.7960\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4679 - sparse_categorical_accuracy: 0.8574 - val_loss: 0.4907 - val_sparse_categorical_accuracy: 0.8559\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4940 - sparse_categorical_accuracy: 0.8470\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.3315 - sparse_categorical_accuracy: 0.5570\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6809 - sparse_categorical_accuracy: 0.7559 - val_loss: 0.6780 - val_sparse_categorical_accuracy: 0.7807\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4755 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.8483\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5152 - sparse_categorical_accuracy: 0.8397\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.5227 - sparse_categorical_accuracy: 0.5253\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7177 - sparse_categorical_accuracy: 0.7539 - val_loss: 0.7400 - val_sparse_categorical_accuracy: 0.7506\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8340 - val_loss: 0.5601 - val_sparse_categorical_accuracy: 0.8231\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.8208\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.1573 - sparse_categorical_accuracy: 0.4345\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9876 - sparse_categorical_accuracy: 0.6797 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.7396\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6295 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.6288 - val_sparse_categorical_accuracy: 0.8120\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6326 - sparse_categorical_accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "# LR layer 1\n",
    "acc_LR = []\n",
    "acc_LR_finetuned = []\n",
    "idx = 5\n",
    "for rank in ranks_layer1:\n",
    "    \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    W = loadedModel.get_layer(index=idx).get_weights()[0]\n",
    "    bias  = loadedModel.get_layer(index=idx).get_weights()[1]\n",
    "    \n",
    "    [U,S,V] = np.linalg.svd(W)\n",
    "    U = np.dot(U[:,:rank], np.diag(S[:rank]))\n",
    "    V = V[:rank, :]\n",
    "                            \n",
    "    low_rank_layer = lowrankLayer(W.shape[0], W.shape[1], rank)\n",
    "    dum = low_rank_layer(tf.ones(shape=(1, W.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer.set_weights([U,V,bias])\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == idx:\n",
    "            new_layer_list.append(low_rank_layer)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_LR.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=2, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_LR_finetuned.append(acc)     \n",
    "\n",
    "acc_LR_layer1 = np.array(acc_LR)\n",
    "acc_LR_finetuned_layer1 = np.array(acc_LR_finetuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4858 - sparse_categorical_accuracy: 0.8570\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2903 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.3991 - val_sparse_categorical_accuracy: 0.8738\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4099 - sparse_categorical_accuracy: 0.8724\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4872 - sparse_categorical_accuracy: 0.8565\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2831 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.3989 - val_sparse_categorical_accuracy: 0.8764\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.3998 - sparse_categorical_accuracy: 0.8778\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4962 - sparse_categorical_accuracy: 0.8526\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2760 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.8618\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4746 - sparse_categorical_accuracy: 0.8554\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5156 - sparse_categorical_accuracy: 0.8450\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3089 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.8705\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4419 - sparse_categorical_accuracy: 0.8683\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5391 - sparse_categorical_accuracy: 0.8359\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3464 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4556 - val_sparse_categorical_accuracy: 0.8581\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4548 - sparse_categorical_accuracy: 0.8610\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8287\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3397 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.8569\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5022 - sparse_categorical_accuracy: 0.8478\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.8192\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3714 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.8429\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5014 - sparse_categorical_accuracy: 0.8409\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6046 - sparse_categorical_accuracy: 0.8139\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4120 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.4648 - val_sparse_categorical_accuracy: 0.8557\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.8534\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6234 - sparse_categorical_accuracy: 0.8068\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4070 - sparse_categorical_accuracy: 0.8672 - val_loss: 0.4853 - val_sparse_categorical_accuracy: 0.8407\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.8401\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.7962\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4478 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.5486 - val_sparse_categorical_accuracy: 0.8210\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5629 - sparse_categorical_accuracy: 0.8177\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8181 - sparse_categorical_accuracy: 0.7345\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5681 - sparse_categorical_accuracy: 0.8262 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.8149\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5982 - sparse_categorical_accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "#nettrim Layer 1\n",
    "U_dict_layer1 = np.load('approx_matrices/net_trim_layer_1_Run2_N_512.npy', allow_pickle=True).item()\n",
    "thr = 0.0001\n",
    "acc_nettrim = []\n",
    "acc_nettrim_finetuned = []\n",
    "nnzs = []\n",
    "idx = 5\n",
    "for epsilon, W in U_dict_layer1.items():\n",
    "    \n",
    "    W[np.abs(W)<=thr] = 0.0\n",
    "    M = np.ones_like(W, dtype=\"float32\")\n",
    "    M[np.abs(W)<=thr] = 0.0\n",
    "    W = W.astype(\"float32\")\n",
    "    M = M.astype(\"float32\")\n",
    "    nnz = np.count_nonzero(W)\n",
    "    nnzs.append(nnz)\n",
    "                            \n",
    "        \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    bias = getLayerBias(loadedModel, idx)\n",
    "    \n",
    "    sparseLayer = sparseLayerlocal(n_input=W.shape[0], n_output=W.shape[1], Wip=W, Mip=M, bias_ip=bias)\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == idx:\n",
    "            new_layer_list.append(sparseLayer)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_nettrim.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=1, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_nettrim_finetuned.append(acc)     \n",
    "\n",
    "acc_nettrim_layer1 = np.array(acc_nettrim)\n",
    "acc_netrim_finetuned_layer1 = np.array(acc_nettrim_finetuned)\n",
    "nnz_layer1 = np.array(nnzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettrimm_size_with_layer_1 = []\n",
    "for nnz in nnz_layer1:\n",
    "    size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  3*nnz  + 120 +  120*84 + 84 +  84*10 +10\n",
    "    nettrimm_size_with_layer_1.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({\"text.usetex\": True})\n",
    "plt.plot(np.array(size_with_layer_1)/initial_size, acc_DLR_layer1/origAccuracy, 'g-*' )\n",
    "plt.plot(np.array(size_with_layer_1)/initial_size, acc_DLR_finetuned_layer1/origAccuracy, 'g--*' )\n",
    "\n",
    "plt.plot(np.array(size_with_layer_1)/initial_size, acc_LR_layer1/origAccuracy, 'r-s' )\n",
    "plt.plot(np.array(size_with_layer_1)/initial_size, acc_LR_finetuned_layer1/origAccuracy, 'r--s' )\n",
    "\n",
    "plt.plot(np.array(nettrimm_size_with_layer_1)/initial_size, acc_nettrim_layer1/origAccuracy, 'b-o' )\n",
    "plt.plot(np.array(nettrimm_size_with_layer_1)/initial_size, acc_netrim_finetuned_layer1/origAccuracy, 'b--o' )\n",
    "\n",
    "plt.xlabel(r'$\\textrm{Size Percentage}$', fontsize='x-large')\n",
    "plt.ylabel(r'$\\frac{\\textrm{Accuracy Compressed}}{\\textrm{Accuracy Original}}$',fontsize='x-large') \n",
    "plt.savefig('Figures/MNIST_layer1_Ntr_512_N_approx_512_full_finetune.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4861 - sparse_categorical_accuracy: 0.8569\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8828 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.8574\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4570 - sparse_categorical_accuracy: 0.8527\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4884 - sparse_categorical_accuracy: 0.8571\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2867 - sparse_categorical_accuracy: 0.9180 - val_loss: 0.4882 - val_sparse_categorical_accuracy: 0.8490\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5075 - sparse_categorical_accuracy: 0.8399\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4970 - sparse_categorical_accuracy: 0.8545\n",
      "8/8 [==============================] - 1s 31ms/step - loss: 0.3071 - sparse_categorical_accuracy: 0.9121 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8643\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4334 - sparse_categorical_accuracy: 0.8685\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5129 - sparse_categorical_accuracy: 0.8479\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.9180 - val_loss: 0.4204 - val_sparse_categorical_accuracy: 0.8720\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4214 - sparse_categorical_accuracy: 0.8733\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5299 - sparse_categorical_accuracy: 0.8428\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3399 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.4291 - val_sparse_categorical_accuracy: 0.8709\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4460 - sparse_categorical_accuracy: 0.8686\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5490 - sparse_categorical_accuracy: 0.8341\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3530 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4779 - val_sparse_categorical_accuracy: 0.8513\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4956 - sparse_categorical_accuracy: 0.8526\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.8212\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3987 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.4764 - val_sparse_categorical_accuracy: 0.8516\n",
      "79/79 [==============================] - 0s 994us/step - loss: 0.4926 - sparse_categorical_accuracy: 0.8453\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.8069\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4061 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4945 - val_sparse_categorical_accuracy: 0.8474\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4945 - sparse_categorical_accuracy: 0.8480\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6328 - sparse_categorical_accuracy: 0.7887\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4321 - sparse_categorical_accuracy: 0.8711 - val_loss: 0.4989 - val_sparse_categorical_accuracy: 0.8441\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.8404\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7025 - sparse_categorical_accuracy: 0.7596\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4808 - sparse_categorical_accuracy: 0.8438 - val_loss: 0.5286 - val_sparse_categorical_accuracy: 0.8302\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5500 - sparse_categorical_accuracy: 0.8212\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8991 - sparse_categorical_accuracy: 0.6670\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.6136 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.6185 - val_sparse_categorical_accuracy: 0.8068\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "# DLR layer 2\n",
    "U_dict_layer2 = np.load('approx_matrices/DLR_layer_2_Run2_N_512.npy',allow_pickle=True).item()\n",
    "thr = 0.1\n",
    "acc_DLR = []\n",
    "acc_DLR_finetuned = []\n",
    "ranks = []\n",
    "idx = 6\n",
    "for epsilon, W in U_dict_layer2.items():\n",
    "\n",
    "    [U, S, V] = np.linalg.svd(W)\n",
    "    #print(S)\n",
    "    rank = np.count_nonzero(S>thr)\n",
    "    U = np.dot(U[:,:rank], np.diag(S[:rank]))\n",
    "    V = V[:rank, :]\n",
    "                            \n",
    "    ranks.append(rank)\n",
    "                            \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    bias = getLayerBias(loadedModel, idx)\n",
    "    \n",
    "    low_rank_layer = lowrankLayer(W.shape[0], W.shape[1], rank)\n",
    "    dum = low_rank_layer(tf.ones(shape=(1, W.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer.set_weights([U,V,bias])\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == idx:\n",
    "            new_layer_list.append(low_rank_layer)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_DLR.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=1, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_DLR_finetuned.append(acc)     \n",
    "\n",
    "acc_DLR_layer2 = np.array(acc_DLR)\n",
    "acc_DLR_finetuned_layer2 = np.array(acc_DLR_finetuned)\n",
    "ranks_layer2 = np.array(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56, 46, 26, 17, 14, 11, 10,  9,  9,  8,  6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_with_layer_2 = []\n",
    "for rank in ranks_layer2:\n",
    "    size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  256*120 + 120 +  (120+84)*rank + 84 +  84*10 +10\n",
    "    size_with_layer_2.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5586 - sparse_categorical_accuracy: 0.8274\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3538 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.4262 - val_sparse_categorical_accuracy: 0.8746\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.2665 - sparse_categorical_accuracy: 0.9277 - val_loss: 0.3962 - val_sparse_categorical_accuracy: 0.8765\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4039 - sparse_categorical_accuracy: 0.8760\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7853\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.4633 - val_sparse_categorical_accuracy: 0.8514\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2875 - sparse_categorical_accuracy: 0.9199 - val_loss: 0.3631 - val_sparse_categorical_accuracy: 0.8888\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.3660 - sparse_categorical_accuracy: 0.8906\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8567 - sparse_categorical_accuracy: 0.7312\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.5341 - sparse_categorical_accuracy: 0.8359 - val_loss: 0.6361 - val_sparse_categorical_accuracy: 0.7992\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3748 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.4241 - val_sparse_categorical_accuracy: 0.8677\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4246 - sparse_categorical_accuracy: 0.8692\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.6395 - sparse_categorical_accuracy: 0.4506\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7702 - sparse_categorical_accuracy: 0.7461 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.8157\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.5064 - sparse_categorical_accuracy: 0.8613 - val_loss: 0.4901 - val_sparse_categorical_accuracy: 0.8633\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4929 - sparse_categorical_accuracy: 0.8627\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.5271 - sparse_categorical_accuracy: 0.4412\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 1s 25ms/step - loss: 0.7689 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.7794\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5232 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.5314 - val_sparse_categorical_accuracy: 0.8416\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5324 - sparse_categorical_accuracy: 0.8440\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.7676 - sparse_categorical_accuracy: 0.4082\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0014 - sparse_categorical_accuracy: 0.6895 - val_loss: 0.9017 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6542 - sparse_categorical_accuracy: 0.8613 - val_loss: 0.6354 - val_sparse_categorical_accuracy: 0.8235\n",
      "79/79 [==============================] - 0s 975us/step - loss: 0.6316 - sparse_categorical_accuracy: 0.8191\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.6900 - sparse_categorical_accuracy: 0.3881\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9404 - sparse_categorical_accuracy: 0.6992 - val_loss: 0.8208 - val_sparse_categorical_accuracy: 0.7782\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.6299 - sparse_categorical_accuracy: 0.8203 - val_loss: 0.6509 - val_sparse_categorical_accuracy: 0.8058\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6464 - sparse_categorical_accuracy: 0.8049\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.9624 - sparse_categorical_accuracy: 0.3589\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0557 - sparse_categorical_accuracy: 0.6660 - val_loss: 0.9728 - val_sparse_categorical_accuracy: 0.7361\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7644 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.8064\n",
      "79/79 [==============================] - 0s 986us/step - loss: 0.6651 - sparse_categorical_accuracy: 0.8009\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.9624 - sparse_categorical_accuracy: 0.3589\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0697 - sparse_categorical_accuracy: 0.6738 - val_loss: 0.9343 - val_sparse_categorical_accuracy: 0.7628\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7229 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.8209\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6417 - sparse_categorical_accuracy: 0.8178\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.0264 - sparse_categorical_accuracy: 0.3467\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1468 - sparse_categorical_accuracy: 0.6562 - val_loss: 1.0006 - val_sparse_categorical_accuracy: 0.7271\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8048 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.8124\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6904 - sparse_categorical_accuracy: 0.8104\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.0176 - sparse_categorical_accuracy: 0.3915\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2088 - sparse_categorical_accuracy: 0.6426 - val_loss: 1.0636 - val_sparse_categorical_accuracy: 0.7075\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8622 - sparse_categorical_accuracy: 0.7715 - val_loss: 0.7840 - val_sparse_categorical_accuracy: 0.7688\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7821 - sparse_categorical_accuracy: 0.7631\n"
     ]
    }
   ],
   "source": [
    "# LR layer 2\n",
    "acc_LR = []\n",
    "acc_LR_finetuned = []\n",
    "idx = 6\n",
    "for rank in ranks_layer2:\n",
    "    \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    W = loadedModel.get_layer(index=idx).get_weights()[0]\n",
    "    bias  = loadedModel.get_layer(index=idx).get_weights()[1]\n",
    "    \n",
    "    [U,S,V] = np.linalg.svd(W)\n",
    "    U = np.dot(U[:,:rank], np.diag(S[:rank]))\n",
    "    V = V[:rank, :]\n",
    "                            \n",
    "    low_rank_layer = lowrankLayer(W.shape[0], W.shape[1], rank)\n",
    "    dum = low_rank_layer(tf.ones(shape=(1, W.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer.set_weights([U,V,bias])\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == idx:\n",
    "            new_layer_list.append(low_rank_layer)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_LR.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=2, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_LR_finetuned.append(acc)     \n",
    "\n",
    "acc_LR_layer2 = np.array(acc_LR)\n",
    "acc_LR_finetuned_layer2 = np.array(acc_LR_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4868 - sparse_categorical_accuracy: 0.8579\n",
      "8/8 [==============================] - 1s 50ms/step - loss: 0.2779 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.3799 - val_sparse_categorical_accuracy: 0.8829\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.3844 - sparse_categorical_accuracy: 0.8846\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4896 - sparse_categorical_accuracy: 0.8571\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3345 - sparse_categorical_accuracy: 0.8828 - val_loss: 0.5782 - val_sparse_categorical_accuracy: 0.8192\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5917 - sparse_categorical_accuracy: 0.8167\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5010 - sparse_categorical_accuracy: 0.8543\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3026 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.4283 - val_sparse_categorical_accuracy: 0.8738\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4363 - sparse_categorical_accuracy: 0.8730\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5147 - sparse_categorical_accuracy: 0.8472\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3586 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.4526 - val_sparse_categorical_accuracy: 0.8597\n",
      "79/79 [==============================] - 0s 997us/step - loss: 0.4690 - sparse_categorical_accuracy: 0.8593\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5287 - sparse_categorical_accuracy: 0.8419\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3209 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.4520 - val_sparse_categorical_accuracy: 0.8563\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4495 - sparse_categorical_accuracy: 0.8616\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.8329\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.4500 - val_sparse_categorical_accuracy: 0.8585\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4515 - sparse_categorical_accuracy: 0.8607\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5709 - sparse_categorical_accuracy: 0.8213\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3626 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.4407 - val_sparse_categorical_accuracy: 0.8651\n",
      "79/79 [==============================] - 0s 994us/step - loss: 0.4588 - sparse_categorical_accuracy: 0.8568\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5924 - sparse_categorical_accuracy: 0.8109\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3927 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.4690 - val_sparse_categorical_accuracy: 0.8514\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4749 - sparse_categorical_accuracy: 0.8510\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6190 - sparse_categorical_accuracy: 0.7990\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4133 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.4595 - val_sparse_categorical_accuracy: 0.8575\n",
      "79/79 [==============================] - 0s 999us/step - loss: 0.4713 - sparse_categorical_accuracy: 0.8545\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6790 - sparse_categorical_accuracy: 0.7768\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.4909 - val_sparse_categorical_accuracy: 0.8425\n",
      "79/79 [==============================] - 0s 999us/step - loss: 0.5007 - sparse_categorical_accuracy: 0.8413\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8873 - sparse_categorical_accuracy: 0.6790\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.8555 - val_loss: 0.5619 - val_sparse_categorical_accuracy: 0.8219\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.8216\n"
     ]
    }
   ],
   "source": [
    "#nettrim Layer 2\n",
    "U_dict_layer2 = np.load('approx_matrices/net_trim_layer_2_Run2_N_512.npy', allow_pickle=True).item()\n",
    "thr = 0.0001\n",
    "acc_nettrim = []\n",
    "acc_nettrim_finetuned = []\n",
    "nnzs = []\n",
    "idx = 6\n",
    "for epsilon, W in U_dict_layer2.items():\n",
    "    \n",
    "    W[np.abs(W)<=thr] = 0.0\n",
    "    M = np.ones_like(W, dtype=\"float32\")\n",
    "    M[np.abs(W)<=thr] = 0.0\n",
    "    W = W.astype(\"float32\")\n",
    "    M = M.astype(\"float32\")\n",
    "    nnz = np.count_nonzero(W)\n",
    "    nnzs.append(nnz)\n",
    "                            \n",
    "        \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    bias = getLayerBias(loadedModel, idx)\n",
    "    \n",
    "    sparseLayer = sparseLayerlocal(n_input=W.shape[0], n_output=W.shape[1], Wip=W, Mip=M, bias_ip=bias)\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == idx:\n",
    "            new_layer_list.append(sparseLayer)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_nettrim.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=1, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_nettrim_finetuned.append(acc)     \n",
    "\n",
    "acc_nettrim_layer2 = np.array(acc_nettrim)\n",
    "acc_netrim_finetuned_layer2 = np.array(acc_nettrim_finetuned)\n",
    "nnz_layer2 = np.array(nnzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettrimm_size_with_layer_2 = []\n",
    "for nnz in nnz_layer2:\n",
    "    size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  256*120 + 120 +  3*nnz + 84 +  84*10 +10\n",
    "    nettrimm_size_with_layer_2.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({\"text.usetex\": True})\n",
    "plt.plot(np.array(size_with_layer_2)/initial_size, acc_DLR_layer2/origAccuracy, 'g-*' )\n",
    "plt.plot(np.array(size_with_layer_2)/initial_size, acc_DLR_finetuned_layer2/origAccuracy, 'g--*' )\n",
    "\n",
    "plt.plot(np.array(size_with_layer_2)/initial_size, acc_LR_layer2/origAccuracy, 'r-s' )\n",
    "plt.plot(np.array(size_with_layer_2)/initial_size, acc_LR_finetuned_layer2/origAccuracy, 'r--s' )\n",
    "\n",
    "plt.plot(np.array(nettrimm_size_with_layer_2)/initial_size, acc_nettrim_layer2/origAccuracy, 'b-o' )\n",
    "plt.plot(np.array(nettrimm_size_with_layer_2)/initial_size, acc_netrim_finetuned_layer2/origAccuracy, 'b--o' )\n",
    "\n",
    "plt.xlabel(r'$\\textrm{Size Percentage}$', fontsize='x-large')\n",
    "plt.ylabel(r'$\\frac{\\textrm{Accuracy Compressed}}{\\textrm{Accuracy Original}}$',fontsize='x-large') \n",
    "plt.savefig('Figures/MNIST_layer2_Ntr_512_N_approx_512_full_finetune.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4880 - sparse_categorical_accuracy: 0.8565\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.4233 - val_sparse_categorical_accuracy: 0.8748\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4287 - sparse_categorical_accuracy: 0.8746\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4950 - sparse_categorical_accuracy: 0.8543\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2976 - sparse_categorical_accuracy: 0.9180 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8700\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.8653\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.8469\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3204 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.4803 - val_sparse_categorical_accuracy: 0.8512\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.8469\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5282 - sparse_categorical_accuracy: 0.8418\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.4059 - val_sparse_categorical_accuracy: 0.8766\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4091 - sparse_categorical_accuracy: 0.8773\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.8305\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.4478 - val_sparse_categorical_accuracy: 0.8564\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4557 - sparse_categorical_accuracy: 0.8582\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5903 - sparse_categorical_accuracy: 0.8210\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4046 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.4579 - val_sparse_categorical_accuracy: 0.8602\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4758 - sparse_categorical_accuracy: 0.8570\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6308 - sparse_categorical_accuracy: 0.7993\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8613 - val_loss: 0.4807 - val_sparse_categorical_accuracy: 0.8495\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.8390\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.7820\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 0.4498 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.8359\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5239 - sparse_categorical_accuracy: 0.8305\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7116 - sparse_categorical_accuracy: 0.7624\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.4952 - sparse_categorical_accuracy: 0.8418 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.8311\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.8276\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8095 - sparse_categorical_accuracy: 0.7219\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.5916 - val_sparse_categorical_accuracy: 0.8082\n",
      "79/79 [==============================] - 0s 997us/step - loss: 0.5985 - sparse_categorical_accuracy: 0.8045\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.0915 - sparse_categorical_accuracy: 0.5874\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8442 - sparse_categorical_accuracy: 0.7344 - val_loss: 0.7362 - val_sparse_categorical_accuracy: 0.7783\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7396 - sparse_categorical_accuracy: 0.7651\n"
     ]
    }
   ],
   "source": [
    "# DLR for both the layers \n",
    "U_dict_layer1 = np.load('approx_matrices/DLR_layer_1_Run2_N_512.npy',allow_pickle=True).item()\n",
    "U_dict_layer2 = np.load('approx_matrices/DLR_layer_2_Run2_N_512.npy',allow_pickle=True).item()\n",
    "acc_DLR = []\n",
    "acc_DLR_finetuned = []\n",
    "ranks = []\n",
    "for key1, key2, rank1, rank2 in zip(U_dict_layer1.keys(), U_dict_layer2.keys(), ranks_layer1, ranks_layer2):\n",
    "    \n",
    "    W1 = U_dict_layer1[key1]\n",
    "    [U1,S1,V1] = np.linalg.svd(W1)\n",
    "    U1 = np.dot(U1[:,:rank1], np.diag(S1[:rank1]))\n",
    "    V1 = V1[:rank1, :]\n",
    "    \n",
    "    W2 = U_dict_layer2[key2]\n",
    "    [U2,S2,V2] = np.linalg.svd(W2)\n",
    "    U2 = np.dot(U2[:,:rank2], np.diag(S2[:rank2]))\n",
    "    V2 = V2[:rank2, :]\n",
    "                            \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    \n",
    "\n",
    "    bias1 = getLayerBias(loadedModel, 5)\n",
    "    low_rank_layer1 = lowrankLayer(W1.shape[0], W1.shape[1], rank1)\n",
    "    dum = low_rank_layer1(tf.ones(shape=(1, W1.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer1.set_weights([U1,V1,bias1])\n",
    "    \n",
    "    bias2 = getLayerBias(loadedModel, 6)\n",
    "    low_rank_layer2 = lowrankLayer(W2.shape[0], W2.shape[1], rank2)\n",
    "    dum = low_rank_layer2(tf.ones(shape=(1, W2.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer2.set_weights([U2,V2,bias2])\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == 5:\n",
    "            new_layer_list.append(low_rank_layer1)\n",
    "        elif i == 6:\n",
    "            new_layer_list.append(low_rank_layer2)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_DLR.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=1, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_DLR_finetuned.append(acc)     \n",
    "\n",
    "acc_DLR_combined= np.array(acc_DLR)\n",
    "acc_DLR_finetuned_combined = np.array(acc_DLR_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_with_combined = []\n",
    "for rank1, rank2 in zip(ranks_layer1, ranks_layer2):\n",
    "    size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  (256 + 120)*rank1 + 120 +  (120+ 84)*rank2 + 84 +  84*10 +10\n",
    "    size_with_combined.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 2ms/step - loss: 0.6001 - sparse_categorical_accuracy: 0.8147\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.4059 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.4730 - val_sparse_categorical_accuracy: 0.8504\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.3052 - sparse_categorical_accuracy: 0.9121 - val_loss: 0.4259 - val_sparse_categorical_accuracy: 0.8646\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4239 - sparse_categorical_accuracy: 0.8694\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7305 - sparse_categorical_accuracy: 0.7636\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4208 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.4795 - val_sparse_categorical_accuracy: 0.8457\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2779 - sparse_categorical_accuracy: 0.9199 - val_loss: 0.3878 - val_sparse_categorical_accuracy: 0.8817\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.3984 - sparse_categorical_accuracy: 0.8776\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.9393 - sparse_categorical_accuracy: 0.6924\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.5596 - val_sparse_categorical_accuracy: 0.8172\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.4182 - val_sparse_categorical_accuracy: 0.8759\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4175 - sparse_categorical_accuracy: 0.8712\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.9330 - sparse_categorical_accuracy: 0.3724\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9716 - sparse_categorical_accuracy: 0.6582 - val_loss: 0.8274 - val_sparse_categorical_accuracy: 0.7625\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.6408 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.8059\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6646 - sparse_categorical_accuracy: 0.8083\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.6532 - sparse_categorical_accuracy: 0.3771\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9427 - sparse_categorical_accuracy: 0.6719 - val_loss: 0.7946 - val_sparse_categorical_accuracy: 0.7762\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.8477 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.8152\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6265 - sparse_categorical_accuracy: 0.8165\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.7980 - sparse_categorical_accuracy: 0.3604\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 1.0723 - sparse_categorical_accuracy: 0.6621 - val_loss: 0.9308 - val_sparse_categorical_accuracy: 0.7613\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7600 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.7212 - val_sparse_categorical_accuracy: 0.8071\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7095 - sparse_categorical_accuracy: 0.8025\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.7076 - sparse_categorical_accuracy: 0.4082\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0729 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.9537 - val_sparse_categorical_accuracy: 0.7427\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7607 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.7306 - val_sparse_categorical_accuracy: 0.7904\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7207 - sparse_categorical_accuracy: 0.7895\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.1060 - sparse_categorical_accuracy: 0.2933\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.2995 - sparse_categorical_accuracy: 0.5586 - val_loss: 1.0691 - val_sparse_categorical_accuracy: 0.7460\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9353 - sparse_categorical_accuracy: 0.7500 - val_loss: 0.8760 - val_sparse_categorical_accuracy: 0.7564\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8574 - sparse_categorical_accuracy: 0.7515\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.1060 - sparse_categorical_accuracy: 0.2933\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.2999 - sparse_categorical_accuracy: 0.5527 - val_loss: 1.0882 - val_sparse_categorical_accuracy: 0.7390\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9169 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.8754 - val_sparse_categorical_accuracy: 0.7597\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8585 - sparse_categorical_accuracy: 0.7603\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.2912 - sparse_categorical_accuracy: 0.2941\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.4406 - sparse_categorical_accuracy: 0.4922 - val_loss: 1.1738 - val_sparse_categorical_accuracy: 0.7280\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0332 - sparse_categorical_accuracy: 0.7637 - val_loss: 0.9567 - val_sparse_categorical_accuracy: 0.7484\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.9415 - sparse_categorical_accuracy: 0.7453\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 2.3353 - sparse_categorical_accuracy: 0.3366\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.5914 - sparse_categorical_accuracy: 0.5078 - val_loss: 1.4368 - val_sparse_categorical_accuracy: 0.4914\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2387 - sparse_categorical_accuracy: 0.6309 - val_loss: 1.1429 - val_sparse_categorical_accuracy: 0.6901\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.1301 - sparse_categorical_accuracy: 0.6904\n"
     ]
    }
   ],
   "source": [
    "# LR for both the layers \n",
    "U_dict_layer1 = np.load('approx_matrices/DLR_layer_1_Run2_N_512.npy', allow_pickle=True).item()\n",
    "U_dict_layer2 = np.load('approx_matrices/DLR_layer_2_Run2_N_512.npy', allow_pickle=True).item()\n",
    "acc_LR = []\n",
    "acc_LR_finetuned = []\n",
    "ranks = []\n",
    "for rank1, rank2 in zip(ranks_layer1, ranks_layer2):\n",
    "    \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    W1 = loadedModel.get_layer(index=5).get_weights()[0]\n",
    "    bias1  = loadedModel.get_layer(index=5).get_weights()[1]\n",
    "    [U1,S1,V1] = np.linalg.svd(W1)\n",
    "    U1 = np.dot(U1[:,:rank1], np.diag(S1[:rank1]))\n",
    "    V1 = V1[:rank1, :]\n",
    "    \n",
    "    W2 = loadedModel.get_layer(index=6).get_weights()[0]\n",
    "    bias2  = loadedModel.get_layer(index=6).get_weights()[1]\n",
    "    [U2,S2,V2] = np.linalg.svd(W2)\n",
    "    U2 = np.dot(U2[:,:rank2], np.diag(S2[:rank2]))\n",
    "    V2 = V2[:rank2, :]\n",
    "                            \n",
    " \n",
    "    low_rank_layer1 = lowrankLayer(W1.shape[0], W1.shape[1], rank1)\n",
    "    dum = low_rank_layer1(tf.ones(shape=(1, W1.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer1.set_weights([U1,V1,bias1])\n",
    "    \n",
    "    bias2 = getLayerBias(loadedModel, 6)\n",
    "    low_rank_layer2 = lowrankLayer(W2.shape[0], W2.shape[1], rank2)\n",
    "    dum = low_rank_layer2(tf.ones(shape=(1, W2.shape[0])))     # for proper initialization   \n",
    "    low_rank_layer2.set_weights([U2,V2,bias2])\n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == 5:\n",
    "            new_layer_list.append(low_rank_layer1)\n",
    "        elif i == 6:\n",
    "            new_layer_list.append(low_rank_layer2)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_LR.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=2, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_LR_finetuned.append(acc)     \n",
    "\n",
    "acc_LR_combined = np.array(acc_LR)\n",
    "acc_LR_finetuned_combined = np.array(acc_LR_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4879 - sparse_categorical_accuracy: 0.8569\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.9199 - val_loss: 0.4730 - val_sparse_categorical_accuracy: 0.8522\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.8441\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4922 - sparse_categorical_accuracy: 0.8554\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.2863 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.8736\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4303 - sparse_categorical_accuracy: 0.8743\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5124 - sparse_categorical_accuracy: 0.8484\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3105 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.4338 - val_sparse_categorical_accuracy: 0.8646\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.8585\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5426 - sparse_categorical_accuracy: 0.8369\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4284 - val_sparse_categorical_accuracy: 0.8663\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4415 - sparse_categorical_accuracy: 0.8641\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5774 - sparse_categorical_accuracy: 0.8215\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3533 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8655\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8619\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6209 - sparse_categorical_accuracy: 0.8028\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3897 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.4675 - val_sparse_categorical_accuracy: 0.8530\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.4717 - sparse_categorical_accuracy: 0.8542\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6639 - sparse_categorical_accuracy: 0.7865\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4241 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.5027 - val_sparse_categorical_accuracy: 0.8412\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5052 - sparse_categorical_accuracy: 0.8386\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7078 - sparse_categorical_accuracy: 0.7665\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4578 - sparse_categorical_accuracy: 0.8672 - val_loss: 0.5293 - val_sparse_categorical_accuracy: 0.8293\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5313 - sparse_categorical_accuracy: 0.8292\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7537 - sparse_categorical_accuracy: 0.7458\n",
      "8/8 [==============================] - 1s 52ms/step - loss: 0.5215 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.5600 - val_sparse_categorical_accuracy: 0.8188\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8182\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.8509 - sparse_categorical_accuracy: 0.7012\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5930 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.6110 - val_sparse_categorical_accuracy: 0.8029\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.6123 - sparse_categorical_accuracy: 0.7999\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 1.1873 - sparse_categorical_accuracy: 0.5577\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8764 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.7649\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.7866 - sparse_categorical_accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "#nettrim Layer 2\n",
    "U_dict_layer1 = np.load('approx_matrices/net_trim_layer_1_Run2_N_512.npy', allow_pickle=True).item()\n",
    "U_dict_layer2 = np.load('approx_matrices/net_trim_layer_2_Run2_N_512.npy', allow_pickle=True).item()\n",
    "thr = 0.0001\n",
    "acc_nettrim = []\n",
    "acc_nettrim_finetuned = []\n",
    "nnzs_1 = []\n",
    "nnzs_2 = []\n",
    "for eps1, eps2 in zip(U_dict_layer1.keys(), U_dict_layer2.keys()):\n",
    "    \n",
    "    W = U_dict_layer1[eps1]\n",
    "    W[np.abs(W)<=thr] = 0.0\n",
    "    M = np.ones_like(W, dtype=\"float32\")\n",
    "    M[np.abs(W)<=thr] = 0.0\n",
    "    W = W.astype(\"float32\")\n",
    "    M = M.astype(\"float32\")\n",
    "    nnz = np.count_nonzero(W)\n",
    "    nnzs_1.append(nnz)\n",
    "                                \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    bias = getLayerBias(loadedModel, 5)\n",
    "    \n",
    "    sparseLayer1 = sparseLayerlocal(n_input=W.shape[0], n_output=W.shape[1], Wip=W, Mip=M, bias_ip=bias)\n",
    "    \n",
    "    W = U_dict_layer2[eps2]\n",
    "    W[np.abs(W)<=thr] = 0.0\n",
    "    M = np.ones_like(W, dtype=\"float32\")\n",
    "    M[np.abs(W)<=thr] = 0.0\n",
    "    W = W.astype(\"float32\")\n",
    "    M = M.astype(\"float32\")\n",
    "    nnz = np.count_nonzero(W)\n",
    "    nnzs_2.append(nnz)\n",
    "                                \n",
    "    loadedModel = keras.models.load_model('Lenet_Mnist_Run2')\n",
    "    bias = getLayerBias(loadedModel, 6)\n",
    "    \n",
    "    sparseLayer2 = sparseLayerlocal(n_input=W.shape[0], n_output=W.shape[1], Wip=W, Mip=M, bias_ip=bias)\n",
    "    \n",
    "    \n",
    "                      \n",
    "    new_layer_list = [keras.Input(shape=(28,28,1))]\n",
    "    for i,layer in enumerate(loadedModel.layers):\n",
    "        if i == 5:\n",
    "            new_layer_list.append(sparseLayer1)\n",
    "        elif i == 6: \n",
    "            new_layer_list.append(sparseLayer2)\n",
    "        else:\n",
    "            #layer.trainable = False\n",
    "            new_layer_list.append(layer)\n",
    "                            \n",
    "    LenetModel_Approx = keras.Sequential(new_layer_list)\n",
    "    LenetModel_Approx.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                   metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_nettrim.append(acc)\n",
    "                            \n",
    "    LenetModel_Approx.fit(train_images, train_labels, batch_size=64, epochs=1, validation_data=(val_images, val_labels))\n",
    "    loss, acc = LenetModel_Approx.evaluate(test_images, test_labels, batch_size=128)\n",
    "    acc_nettrim_finetuned.append(acc)     \n",
    "\n",
    "acc_nettrim_combined = np.array(acc_nettrim)\n",
    "acc_nettrim_finetuned_combined= np.array(acc_nettrim_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_nettrim_combined = []\n",
    "for nnz_1, nnz_2 in zip(nnzs_1, nnzs_2):\n",
    "    #size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  nnz_1 + nnz_1*np.log2(256*120)/32 + 120 + nnz_2 + nnz_2*np.log2(120*84)/32 + 84 +  84*10 +10\n",
    "    size =  6*5*5*1 + 6  + 16*5*5*6 + 16 +  3*nnz_1  + 120 + 3*nnz_2  + 84 +  84*10 +10 # for csr format\n",
    "    size_nettrim_combined.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$\\\\frac{\\\\textrm{Accuracy Compressed}}{\\\\textrm{Accuracy Original}}$')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({\"text.usetex\": True})\n",
    "plt.plot(np.array(size_with_combined)/initial_size, acc_DLR_combined/origAccuracy, 'g-*' )\n",
    "#plt.plot(np.array(size_with_combined)/initial_size, acc_DLR_finetuned_combined/origAccuracy, 'g--*' )\n",
    "\n",
    "#plt.plot(np.array(size_with_combined)/initial_size, acc_LR_combined/origAccuracy, 'r-s' )\n",
    "plt.plot(np.array(size_with_combined)/initial_size, acc_LR_finetuned_combined/origAccuracy, 'r-^' )\n",
    "\n",
    "plt.plot(np.array(size_nettrim_combined)/initial_size, acc_nettrim_combined/origAccuracy, 'b-o' )\n",
    "#plt.plot(np.array(size_nettrim_combined)/initial_size, acc_nettrim_finetuned_combined/origAccuracy, 'b--o' )\n",
    "\n",
    "plt.xlabel(r'$\\textrm{Size Percentage}$', fontsize='x-large')\n",
    "plt.ylabel(r'$\\frac{\\textrm{Accuracy Compressed}}{\\textrm{Accuracy Original}}$',fontsize='x-large') \n",
    "#plt.savefig('Figures/MNIST_combined_Ntr_512_N_approx_512_full_finetune.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_x ||RelU(UVx+b) - Relu(Wx+b)||_2^2 vs. U,V from low rank of W, then finetune the entire model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
